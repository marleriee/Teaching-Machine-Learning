# Step 1: Import libraries
import pandas as pd
from sklearn.tree import DecisionTreeClassifier, plot_tree
import matplotlib.pyplot as plt

# Step 2: Load dataset from GitHub
url = 'https://raw.githubusercontent.com/your-username/runners_ml_dataset/main/runners_data_extended.csv'
data = pd.read_csv(url)

# Step 3: Encode categorical variables
# Binary Yes/No variables
binary_cols = ['Running>10h', 'Fatigue', 'MenstrualDisturbance', 'IntuitiveRest']
for col in binary_cols:
    data[col] = data[col].map({'Yes':1, 'No':0})

# CarbonShoe: One-hot encoding
data = pd.get_dummies(data, columns=['CarbonShoe'], drop_first=True)

# Step 4: Split features and target
X = data[['Running>10h', 'Fatigue', 'MenstrualDisturbance', 
          'IntuitiveRest', 'BodyWeight', 'KcalPerDay',
          'CarbonShoe_No', 'CarbonShoe_Sometimes']]
y = data['OveruseFracture'].map({'Yes':1, 'No':0})

# Step 5: Train Decision Tree
clf = DecisionTreeClassifier(max_depth=4, random_state=42)  # slightly deeper for more variables
clf.fit(X, y)

# Step 6: Visualize the tree
plt.figure(figsize=(16,10))
plot_tree(clf, feature_names=X.columns, class_names=['No Fracture','Fracture'], filled=True, rounded=True)
plt.show()

# Step 7: Print leaf probabilities
n_nodes = clf.tree_.node_count
children_left = clf.tree_.children_left
children_right = clf.tree_.children_right
value = clf.tree_.value

print("\nLeaf node probabilities (Overuse Fracture):")
for i in range(n_nodes):
    if children_left[i] == children_right[i]:  # leaf
        total = value[i].sum()
        prob = value[i][0][1]/total
        print(f"Leaf {i}: Probability of fracture = {prob:.2f}, samples = {int(total)}")
